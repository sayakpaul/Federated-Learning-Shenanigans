{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toy example of federated learning with syft.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMBazvwAkLTu",
        "colab_type": "text"
      },
      "source": [
        "Currently, I am taking the course [Secure and Private AI](https://www.udacity.com/course/secure-and-private-ai--ud185) on Udacity. The course is very well curated and is amazingly taught by none other than Andrew Trask. This notebook demonstrates a toy example where I am using Federated Learning using the `syft` framework for training a shallow neural network. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leTArdSOUSRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install syft\n",
        "!pip install syft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2Mv_JoBVIGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import syft and torch\n",
        "import syft\n",
        "import torch\n",
        "\n",
        "# Create syft hook to modify the torch functionalities\n",
        "hook = syft.TorchHook(torch)\n",
        "# Create a remote worker\n",
        "bob = syft.VirtualWorker(hook, id='bob')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8SOomcMUTfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ignore unnecessary warnings and set the random seed\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "np.random.seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzoSwk-jUkZ1",
        "colab_type": "code",
        "outputId": "dcc942da-814d-4d86-b072-e26fc0fb56d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# Data loading preview\n",
        "import pandas as pd\n",
        "\n",
        "columns = [\"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
        "        \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
        "        \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"]\n",
        "\n",
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',\n",
        "                    header=None,\n",
        "                    names=columns)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>WorkClass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>Education</th>\n",
              "      <th>EducationNum</th>\n",
              "      <th>MaritalStatus</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>Relationship</th>\n",
              "      <th>Race</th>\n",
              "      <th>Gender</th>\n",
              "      <th>CapitalGain</th>\n",
              "      <th>CapitalLoss</th>\n",
              "      <th>HoursPerWeek</th>\n",
              "      <th>NativeCountry</th>\n",
              "      <th>Income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age          WorkClass  fnlwgt  ... HoursPerWeek   NativeCountry  Income\n",
              "0   39          State-gov   77516  ...           40   United-States   <=50K\n",
              "1   50   Self-emp-not-inc   83311  ...           13   United-States   <=50K\n",
              "2   38            Private  215646  ...           40   United-States   <=50K\n",
              "3   53            Private  234721  ...           40   United-States   <=50K\n",
              "4   28            Private  338409  ...           40            Cuba   <=50K\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxxfu9AGUm0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting w.r.t fixed indexes rather than random splitting\n",
        "train = data[:30561]\n",
        "test = data[30561:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2H1sfj9UqcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting the categorical and non-categorical features\n",
        "cat_feats = [column for column in data.columns if data[column].dtypes=='object']\n",
        "non_cat_feats = [column for column in data.columns if data[column].dtypes!='object']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJkg4RFVUwRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Label encode categories\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "train[cat_feats] = train[cat_feats].apply(LabelEncoder().fit_transform)\n",
        "test[cat_feats] = test[cat_feats].apply(LabelEncoder().fit_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WtD21SgUyX8",
        "colab_type": "code",
        "outputId": "b3726bf0-7dbe-45b4-ce07-75d1d98261ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Split the data w.r.t fixed set of indices\n",
        "X_train = train.iloc[:,0:-1]\n",
        "y_train = train['Income']\n",
        "\n",
        "X_test = test.iloc[:,0:-1]\n",
        "y_test = test['Income']\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30561, 14), (30561,), (2000, 14), (2000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPME8qXmU06a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standard scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaled_train = StandardScaler().fit_transform(X_train[non_cat_feats].values)\n",
        "scaled_test = StandardScaler().fit_transform(X_test[non_cat_feats].values)\n",
        "\n",
        "X_train[non_cat_feats] = scaled_train\n",
        "X_test[non_cat_feats] = scaled_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCshNjYkU3Uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a custom dataset to load the data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TabularDataset(Dataset):\n",
        "  def __init__(self, data, cat_cols=None, output_col=None):\n",
        "    \"\"\"\n",
        "    Courtesy: https://yashuseth.blog/2018/07/22/pytorch-neural-network-for-tabular-data-with-categorical-embeddings/\n",
        "    \"\"\"\n",
        "\n",
        "    self.n = data.shape[0]\n",
        "\n",
        "    if output_col:\n",
        "      self.y = data[output_col].astype(np.float32).values.reshape(-1, 1)\n",
        "    else:\n",
        "      self.y =  np.zeros((self.n, 1))\n",
        "\n",
        "    self.cat_cols = cat_cols if cat_cols else []\n",
        "    self.cont_cols = [col for col in data.columns\n",
        "                      if col not in self.cat_cols + [output_col]]\n",
        "\n",
        "    if self.cont_cols:\n",
        "      self.cont_X = data[self.cont_cols].astype(np.float32).values\n",
        "    else:\n",
        "      self.cont_X = np.zeros((self.n, 1))\n",
        "\n",
        "    if self.cat_cols:\n",
        "      self.cat_X = data[cat_cols].astype(np.int64).values\n",
        "    else:\n",
        "      self.cat_X =  np.zeros((self.n, 1))\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"\n",
        "    Denotes the total number of samples.\n",
        "    \"\"\"\n",
        "    return self.n\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    \"\"\"\n",
        "    Generates one sample of data.\n",
        "    \"\"\"\n",
        "    return [self.y[idx], self.cont_X[idx], self.cat_X[idx]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkPJpxUOU5Gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Append the labels\n",
        "train = X_train\n",
        "train['Income'] = y_train\n",
        "\n",
        "test = X_test\n",
        "test['Income'] = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_w5QvHdU7GS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the datasets\n",
        "train_data = TabularDataset(data=train, cat_cols=cat_feats[:-1],\n",
        "                             output_col='Income')\n",
        "\n",
        "test_data = TabularDataset(data=test, cat_cols=cat_feats[:-1],\n",
        "                             output_col='Income')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIT9F91BU8xX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare the dataloaders\n",
        "train_loader = DataLoader(train_data, 64)\n",
        "test_loader = DataLoader(test_data, 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piPvG0rKVBZn",
        "colab_type": "code",
        "outputId": "2b5728ea-9667-419e-9e39-646686b4a7f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check one sample\n",
        "y, cont_x, cat_x = next(iter(train_loader))\n",
        "y.shape, cont_x.shape, cat_x.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 1]), torch.Size([64, 6]), torch.Size([64, 8]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzl2U2XkVD_M",
        "colab_type": "code",
        "outputId": "bdef1a74-9abc-4914-d76c-2b5ff0cd95c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "# Model definition\n",
        "model = nn.Sequential(nn.Linear(14, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(p=0.2),\n",
        "                      nn.Linear(64, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(p=0.2),\n",
        "                      nn.Linear(64, 1),\n",
        "                      nn.Sigmoid())\n",
        "model"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=14, out_features=64, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Dropout(p=0.2)\n",
              "  (3): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (4): ReLU()\n",
              "  (5): Dropout(p=0.2)\n",
              "  (6): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (7): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwzWEzaHas60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Send the model to a remote worker Bob\n",
        "model = model.send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3Yb6SowVGML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKAWGqZJVPkN",
        "colab_type": "code",
        "outputId": "737001d9-df7b-43fe-b06b-bc295813ea19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "# Train and validation\n",
        "train_losses, test_losses = [], []\n",
        "for e in range(40):\n",
        "    running_loss = 0\n",
        "    for y, cat_x, cont_x in train_loader:\n",
        "      \n",
        "        concat = torch.cat((cat_x.type(torch.float), cont_x.type(torch.float)), 1)\n",
        "        # Send the features to Bob\n",
        "        concat = concat.view(concat.shape[0], -1).send(bob)\n",
        "        # Send the labels to Bob\n",
        "        y = y.type(torch.float).send(bob)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        # Computation is happening on Bob's worker\n",
        "        preds = model(concat)\n",
        "        # Retrieve the tesnors\n",
        "        preds = preds.get()\n",
        "        y = y.get()\n",
        "        loss = criterion(preds, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    else:\n",
        "        test_loss = 0\n",
        "        accuracy = 0\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for y, cat_x, cont_x in test_loader:\n",
        "              concat = torch.cat((cat_x.type(torch.float), cont_x.type(torch.float)), 1)\n",
        "              concat = concat.view(concat.shape[0], -1).send(bob)\n",
        "              \n",
        "              y = y.type(torch.float).send(bob)\n",
        "              \n",
        "              preds = model(concat)\n",
        "              preds = preds.get()\n",
        "              y = y.get()\n",
        "              test_loss += criterion(preds, y)\n",
        "              _, top_class = preds.topk(1, dim=1)\n",
        "              equals = top_class.type(torch.float) == y.type(torch.float)\n",
        "              accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "        model.train()     \n",
        "        \n",
        "        train_losses.append(running_loss/len(train_loader))\n",
        "        test_losses.append(test_loss/len(test_loader))\n",
        "        \n",
        "        print(\"Epoch: {}/{}.. \".format(e+1, 40),\n",
        "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
        "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/40..  Training Loss: 6.639..  Test Loss: 7.127..  Test Accuracy: 0.742\n",
            "Epoch: 2/40..  Training Loss: 6.645..  Test Loss: 7.086..  Test Accuracy: 0.744\n",
            "Epoch: 3/40..  Training Loss: 6.617..  Test Loss: 7.141..  Test Accuracy: 0.742\n",
            "Epoch: 4/40..  Training Loss: 6.617..  Test Loss: 7.141..  Test Accuracy: 0.742\n",
            "Epoch: 5/40..  Training Loss: 6.617..  Test Loss: 7.072..  Test Accuracy: 0.744\n",
            "Epoch: 6/40..  Training Loss: 6.645..  Test Loss: 7.141..  Test Accuracy: 0.742\n",
            "Epoch: 7/40..  Training Loss: 6.617..  Test Loss: 7.127..  Test Accuracy: 0.742\n",
            "Epoch: 8/40..  Training Loss: 6.617..  Test Loss: 7.086..  Test Accuracy: 0.744\n",
            "Epoch: 9/40..  Training Loss: 6.617..  Test Loss: 7.086..  Test Accuracy: 0.744\n",
            "Epoch: 10/40..  Training Loss: 6.617..  Test Loss: 7.100..  Test Accuracy: 0.743\n",
            "Epoch: 11/40..  Training Loss: 6.617..  Test Loss: 7.072..  Test Accuracy: 0.744\n",
            "Epoch: 12/40..  Training Loss: 6.617..  Test Loss: 7.141..  Test Accuracy: 0.742\n",
            "Epoch: 13/40..  Training Loss: 6.617..  Test Loss: 7.086..  Test Accuracy: 0.744\n",
            "Epoch: 14/40..  Training Loss: 6.617..  Test Loss: 7.127..  Test Accuracy: 0.742\n",
            "Epoch: 15/40..  Training Loss: 6.617..  Test Loss: 7.127..  Test Accuracy: 0.742\n",
            "Epoch: 16/40..  Training Loss: 6.617..  Test Loss: 7.113..  Test Accuracy: 0.743\n",
            "Epoch: 17/40..  Training Loss: 6.617..  Test Loss: 7.141..  Test Accuracy: 0.742\n",
            "Epoch: 18/40..  Training Loss: 6.617..  Test Loss: 7.100..  Test Accuracy: 0.743\n",
            "Epoch: 19/40..  Training Loss: 6.645..  Test Loss: 7.113..  Test Accuracy: 0.743\n",
            "Epoch: 20/40..  Training Loss: 6.617..  Test Loss: 7.086..  Test Accuracy: 0.744\n",
            "Epoch: 21/40..  Training Loss: 6.645..  Test Loss: 7.072..  Test Accuracy: 0.744\n",
            "Epoch: 22/40..  Training Loss: 6.645..  Test Loss: 7.086..  Test Accuracy: 0.744\n",
            "Epoch: 23/40..  Training Loss: 6.645..  Test Loss: 7.127..  Test Accuracy: 0.742\n",
            "Epoch: 24/40..  Training Loss: 6.617..  Test Loss: 7.113..  Test Accuracy: 0.743\n",
            "Epoch: 25/40..  Training Loss: 6.645..  Test Loss: 7.086..  Test Accuracy: 0.744\n",
            "Epoch: 26/40..  Training Loss: 6.617..  Test Loss: 7.113..  Test Accuracy: 0.743\n",
            "Epoch: 27/40..  Training Loss: 6.617..  Test Loss: 7.141..  Test Accuracy: 0.742\n",
            "Epoch: 28/40..  Training Loss: 6.617..  Test Loss: 7.154..  Test Accuracy: 0.741\n",
            "Epoch: 29/40..  Training Loss: 6.617..  Test Loss: 7.086..  Test Accuracy: 0.744\n",
            "Epoch: 30/40..  Training Loss: 6.617..  Test Loss: 7.100..  Test Accuracy: 0.743\n",
            "Epoch: 31/40..  Training Loss: 6.617..  Test Loss: 7.141..  Test Accuracy: 0.742\n",
            "Epoch: 32/40..  Training Loss: 6.617..  Test Loss: 7.127..  Test Accuracy: 0.742\n",
            "Epoch: 33/40..  Training Loss: 6.617..  Test Loss: 7.100..  Test Accuracy: 0.743\n",
            "Epoch: 34/40..  Training Loss: 6.617..  Test Loss: 7.127..  Test Accuracy: 0.742\n",
            "Epoch: 35/40..  Training Loss: 6.645..  Test Loss: 7.113..  Test Accuracy: 0.743\n",
            "Epoch: 36/40..  Training Loss: 6.617..  Test Loss: 7.100..  Test Accuracy: 0.743\n",
            "Epoch: 37/40..  Training Loss: 6.617..  Test Loss: 7.141..  Test Accuracy: 0.742\n",
            "Epoch: 38/40..  Training Loss: 6.617..  Test Loss: 7.113..  Test Accuracy: 0.743\n",
            "Epoch: 39/40..  Training Loss: 6.617..  Test Loss: 7.100..  Test Accuracy: 0.743\n",
            "Epoch: 40/40..  Training Loss: 6.645..  Test Loss: 7.100..  Test Accuracy: 0.743\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}